{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WiDS Recife Live Coding - Sessão 07 [v1.0].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwfxZePU1AyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhz52e7SnbsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/widsrecife/dados/master/datathon2020/training_v2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGBtGEzF6Xd5",
        "colab_type": "code",
        "outputId": "250f352a-a977-4c3a-b477-de3c37df4a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91713, 186)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YP4W9Ff5M29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separando a coluna das labels\n",
        "\n",
        "y = df[\"hospital_death\"]\n",
        "X = df.drop(columns=\"hospital_death\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8X-wF4j5VXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agrupando as colunas por tipo\n",
        "\n",
        "all_columns = X.columns.tolist()\n",
        "\n",
        "columns_id = ['encounter_id', 'patient_id', 'hospital_id', 'icu_id']\n",
        "\n",
        "columns = list(filter(lambda x: x not in columns_id, all_columns))\n",
        "\n",
        "continuous_features = X[columns].select_dtypes(exclude='object').columns.tolist()\n",
        "categorical_features = X[columns].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "\n",
        "columns_first_hour = list(filter((lambda x: \"h1_\" in x),columns))\n",
        "columns_first_day = list(filter((lambda x: \"d1_\" in x),columns))\n",
        "\n",
        "columns_not_time_related = list(filter((lambda x: x not in columns_first_hour and x not in columns_first_day),columns))\n",
        "\n",
        "columns_apache = list(filter((lambda x: \"apache\" in x),columns_not_time_related))\n",
        "columns_not_apache = list(filter((lambda x: \"apache\" not in x),columns_not_time_related))\n",
        "\n",
        "assert len(columns) == len(columns_not_time_related) + len(columns_first_hour) + len(columns_first_day)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPfaLAuU58ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separando 40% dos dados para a gente testar depois\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.40, random_state=42, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPe1P6btngp_",
        "colab_type": "text"
      },
      "source": [
        "## Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM6gB_eUx9kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modelo com parâmetros default\n",
        "modelo = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNy2CgFj6s8c",
        "colab_type": "code",
        "outputId": "8f24aa1b-03d2-4b8c-b059-b3258973f4dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "# Treinar o modelo\n",
        "modelo.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-99b6c755ab91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Other/Unknown'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqKQ9Zau7I-v",
        "colab_type": "text"
      },
      "source": [
        "## Explorando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mRXd7dk79lr",
        "colab_type": "code",
        "outputId": "cb3da654-7273-4dc8-dee5-c0068f0bfc43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "X_train.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encounter_id                     int64\n",
              "patient_id                       int64\n",
              "hospital_id                      int64\n",
              "age                            float64\n",
              "bmi                            float64\n",
              "                                ...   \n",
              "leukemia                       float64\n",
              "lymphoma                       float64\n",
              "solid_tumor_with_metastasis    float64\n",
              "apache_3j_bodysystem            object\n",
              "apache_2_bodysystem             object\n",
              "Length: 185, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Fukc7LnLF2",
        "colab_type": "code",
        "outputId": "5c01956f-e3a9-4f1a-811c-3f0b866551f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "missing_value_stats = X_train.isnull().sum(axis=0).sort_values(ascending=False)\n",
        "missing_value_stats[missing_value_stats != 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "h1_bilirubin_min    50792\n",
              "h1_bilirubin_max    50792\n",
              "h1_lactate_max      50633\n",
              "h1_lactate_min      50633\n",
              "h1_albumin_min      50300\n",
              "                    ...  \n",
              "d1_sysbp_max           86\n",
              "d1_heartrate_max       81\n",
              "d1_heartrate_min       81\n",
              "icu_admit_source       71\n",
              "gender                 14\n",
              "Length: 175, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GotAMdd9wwR",
        "colab_type": "text"
      },
      "source": [
        "## Criando nossa primeira pipeline\n",
        "1. Selecionar as colunas que vamos utilizar no modelo\n",
        "2. Preencher valores faltantes\n",
        "3. Fazer o one-hot-encoding apenas nas colunas categóricas\n",
        "4. Treinar o modelo usando o RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTS2rcdnopM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criando os steps\n",
        "\n",
        "# 1. selecionar as colunas que vamos utilizar\n",
        "def selecionar_colunas(X):\n",
        "    return X[continuous_features+categorical_features]\n",
        "\n",
        "step_1 = FunctionTransformer(selecionar_colunas, validate=False)\n",
        "\n",
        "# 2. preencher valores faltantes\n",
        "step_2 = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "# 3. one-hot-encoding apenas nas colunas categóricas\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "# precisamos selecionar as colunas categóricas pelo indice e não pelo nome da coluna\n",
        "categorical_features_indices = np.where(X_train[continuous_features+categorical_features].dtypes == np.object)[0]\n",
        "\n",
        "step_3 = ColumnTransformer([(\"one-hot-encoding\", one_hot_encoder, categorical_features_indices)],\n",
        "                           remainder=\"passthrough\")\n",
        "\n",
        "# 4. treinar o modelo\n",
        "step_4 = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkR7JmbBA6kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montando a pipeline\n",
        "primeira_pipeline = Pipeline([(\"selecionar_colunas\", step_1),\n",
        "                              (\"preencher_valores_faltantes\", step_2),\n",
        "                              (\"one_hot_encoding\", step_3),\n",
        "                              (\"modelo\", step_4)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzSSCz9ABTYe",
        "colab_type": "text"
      },
      "source": [
        "## Treinando o modelo usando a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjmZcBCZBWED",
        "colab_type": "code",
        "outputId": "58537b37-875a-4807-f60e-128d2bc66f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "primeira_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('selecionar_colunas',\n",
              "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
              "                                     func=<function selecionar_colunas at 0x7f4d525b4bf8>,\n",
              "                                     inv_kw_args=None, inverse_func=None,\n",
              "                                     kw_args=None, validate=False)),\n",
              "                ('preencher_valores_faltantes',\n",
              "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
              "                               missing_values=nan, strategy='most_f...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5-fxCRYBagr",
        "colab_type": "text"
      },
      "source": [
        "## Avaliando o modelo com os dados que separamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWGmcrPxBdp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicoes = primeira_pipeline.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY8sn4P54WzH",
        "colab_type": "code",
        "outputId": "28094dea-3d35-4711-f7f2-72b8ba961551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "predicoes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81, 0.19],\n",
              "       [0.99, 0.01],\n",
              "       [0.43, 0.57],\n",
              "       ...,\n",
              "       [0.99, 0.01],\n",
              "       [0.87, 0.13],\n",
              "       [0.59, 0.41]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSJ3O3uaBizn",
        "colab_type": "code",
        "outputId": "e83a8385-cf0a-4fd3-a0a4-b22e2757c050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "roc_auc_score(y_test, predicoes[:,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8847274451322751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3UKvMf4Bse1",
        "colab_type": "text"
      },
      "source": [
        "## Gerando dados para mandar para a competição no Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IPP-aF9BzhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# O scikit gera duas colunas, uma para a classe 0 e outra para a classe um\n",
        "primeira_pipeline.classes_\n",
        "\n",
        "# Queremos os scores da classe 1 (a probabilidade do paciente morrer)\n",
        "df_kaggle_predicoes = pd.read_csv(\"https://raw.githubusercontent.com/widsrecife/dados/master/datathon2020/unlabeled.csv\")\n",
        "predicoes_kaggle_scores = primeira_pipeline.predict_proba(df_kaggle_predicoes)[:, 1]\n",
        "\n",
        "# No kaggle os dados precisam de duas colunas: encounter_id e hospital_death\n",
        "predicoes_kaggle_imput = pd.DataFrame(predicoes_kaggle_scores)\n",
        "predicoes_kaggle_imput[\"encounter_id\"] = df_kaggle_predicoes[\"encounter_id\"] #pegamos os valores do dataset completo\n",
        "predicoes_kaggle_imput.columns = [\"hospital_death\",\"encounter_id\"] # renomeando as colunas\n",
        "predicoes_kaggle_imput[[\"encounter_id\",\"hospital_death\"]].to_csv(\"primeira_predicao_random_forest_default.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}